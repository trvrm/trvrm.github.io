<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Software - trvrm</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href="/images/favicon.png" rel="icon">


    <meta name="author" content="trvrm" />
    <meta name="keywords" content="Software" />

    <!-- Open Graph tags -->
        <meta property="og:site_name" content="trvrm" />
        <meta property="og:type" content="website"/>
        <meta property="og:title" content="trvrm"/>
        <meta property="og:url" content=""/>
        <meta property="og:description" content="trvrm"/>


    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.flatly.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/tango.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>





</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
trvrm            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                        <li >
                            <a href="/category/database.html">Database</a>
                        </li>
                        <li class="active">
                            <a href="/category/software.html">Software</a>
                        </li>
                        <li >
                            <a href="/category/systems.html">Systems</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><a href="/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
            <article>
                <h2><a href="/image-recognition-with-keras-tensorflow-and-inceptionv3.html">Image recognition with Keras, Tensorflow, and InceptionV3</a></h2>
                
                
                <div class="entry-content">

                    <p>Neural networks are a powerful tool for teaching computers to recognize complex patterns, and now tools like <a href="https://keras.io/">Keras</a> and <a href="https://www.tensorflow.org/">TensorFlow</a> are beginning to make them a practical tool for programmers who don't have a PhD in machine learning.</p>
<p>One very powerful aspect of these tools is the ability to share pre-trained models with others. There are many tutorials and courses that will walk you through the process of building a neural net and training it on some data set.  But in other areas of software development we are far more likely to use off-the-shelf implementations of common algorithms rather than rolling them ourselves.  We might work through implementing a sort algorithm or a binary tree in order to better understand the concepts, but having done so we almost always end up using the algorithms that come built in to our language or programming environment.</p>
<p>I suspect we'll see the same sort of thing happen in the machine learning world. While being able to train models on our own data will continue to be extremely valuable, there will be many cases where a model already exists that does what we want, and we'll just want to plug it in to our data.</p>
<p>Keras already provides some pre-trained models: in this article, I'll use the <a href="https://www.tensorflow.org/tutorials/image_recognition">Inception V3</a> model to classify an image.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">keras</span>
</pre></div>


<div class="highlight"><pre><span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">keras.applications.inception_v3</span> <span class="kn">import</span> <span class="n">decode_predictions</span>
<span class="kn">from</span> <span class="nn">keras.applications.inception_v3</span> <span class="kn">import</span> <span class="n">preprocess_input</span>
</pre></div>


<h3>Load the pre-trained model</h3>
<div class="highlight"><pre><span class="n">inception</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">inception_v3</span><span class="o">.</span><span class="n">InceptionV3</span><span class="p">(</span>
    <span class="n">include_top</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> 
    <span class="n">input_tensor</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
    <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></div>


<p>(This actually downloads the weights from github.  Keras saves your model files in <code>~/.keras/models</code> in the <a href="https://en.wikipedia.org/wiki/Hierarchical_Data_Format">HDF5</a> file format.)</p>
<div class="highlight"><pre><span class="err">!</span><span class="n">ls</span>  <span class="o">~/.</span><span class="n">keras</span><span class="o">/</span><span class="n">models</span>
</pre></div>


<div class="highlight"><pre>inception_v3_weights_tf_dim_ordering_tf_kernels.h5
</pre></div>


<div class="highlight"><pre><span class="n">inception</span>
</pre></div>


<div class="highlight"><pre>&lt;keras.engine.training.Model at 0x7f6946e537b8&gt;
</pre></div>


<div class="highlight"><pre><span class="n">inception</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre>____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 299, 299, 3)   0                                            
____________________________________________________________________________________________________
conv2d_1 (Conv2D)                (None, 149, 149, 32)  864                                          
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 149, 149, 32)  96


(snipped several hundred lines here...)



mixed10 (Concatenate)            (None, 8, 8, 2048)    0                                            
____________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2D (None, 2048)          0                                            
____________________________________________________________________________________________________
predictions (Dense)              (None, 1000)          2049000                                      
====================================================================================================
Total params: 23,851,784.0
Trainable params: 23,817,352.0
Non-trainable params: 34,432.0
____________________________________________________________________________________________________
</pre></div>


<h3>Now let's load an image and see if Inception can recognize it</h3>
<div class="highlight"><pre><span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="s1">&#39;./hamster.jpg&#39;</span><span class="p">,</span><span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">299</span><span class="p">,</span><span class="mi">299</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span class="n">img</span>
</pre></div>


<p><img alt="png" src="images/inception/output_14_0.png" /></p>
<p>Keras requires the input data to be in a specific shape.</p>
<div class="highlight"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>


<div class="highlight"><pre>(1, 299, 299, 3)
</pre></div>


<div class="highlight"><pre><span class="n">predictions</span> <span class="o">=</span> <span class="n">inception</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">prediction</span>  <span class="o">=</span> <span class="n">decode_predictions</span><span class="p">(</span><span class="n">predictions</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">prediction</span>
</pre></div>


<div class="highlight"><pre>(&#39;n02342885&#39;, &#39;hamster&#39;, 0.91639304)
</pre></div>


<h3>And we're done</h3>
<p>Inception is pretty confident that this is a picture of a hamster.  Without having 
to do any training ourselves, or really having to know anything at all about neural networks,
we've leveraged a publicly available model to classify our image.</p>
                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/basic-keras-example.html">Basic Keras Example</a></h2>
                
                
                <div class="entry-content">

                    <p><a href="https://keras.io/">Keras</a> is a high-level neural network Python library, designed to sit on top of lower level implementations such as <a href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<p>It provides abstractions that enable you to quickly create neural network structures.  Here I'm going to try to create a simple 3 layer network, and use it to solve a basic classification problem.</p>
<p>For reference, the problem I'm trying to solve, and the network I'm using to solve it, are roughly equivalent to <a href="http://playground.tensorflow.org/#activation=relu&amp;regularization=L1&amp;batchSize=10&amp;dataset=xor&amp;regDataset=reg-plane&amp;learningRate=0.003&amp;regularizationRate=0.001&amp;noise=0&amp;networkShape=4,1&amp;seed=0.92802&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">this interactive example  at playground.tensorflow.org</a></p>
<p><strong>Tell Jupyter to display matlplotlib plots directly in the notebook</strong></p>
<div class="highlight"><pre><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>


<h3>Imports</h3>
<p>A lot of machine learning work ends up being about 'housekeeping' - finding, filtering, parsing, loading data, transforming it into a usable shape, and so on.  The <a href="http://pandas.pydata.org/">Pandas</a> library is excellent for this type of work</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</pre></div>


<p>Numpy is commonly used for creating and managing arrays of numbers and performing a wide variety of mathematical operations on them.  Matplotlib and seaborn provide a number of useful plotting functions.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pl</span>
</pre></div>


<div class="highlight"><pre><span class="kn">import</span> <span class="nn">seaborn</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</pre></div>


<p>TensorFlow is Google's Machine Learning library</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</pre></div>


<p>This is a useful function for splitting data sets into training and testing subsets.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>


<p>And finally Keras is the library I actually want to explore.  My understanding is that it provides a high-level abstraction to common TensorFlow operations</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span>
</pre></div>


<h1>Create training data.</h1>
<p>I'm going to create an array of data with two features, <em>x1</em> and <em>x2</em></p>
<div class="highlight"><pre><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1500</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="mi">20</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span><span class="s1">&#39;x2&#39;</span><span class="p">])</span>
</pre></div>


<p>For simpler visualisation, I'm going to filter out values that lie very close to the axes.</p>
<div class="highlight"><pre><span class="n">data</span><span class="o">=</span> <span class="n">data</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x1</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">)</span><span class="o">&amp;</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x2</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">)][</span><span class="mi">0</span><span class="p">:</span><span class="mi">1000</span><span class="p">]</span>
</pre></div>


<p>And then for each <code>(x1,x2)</code> pair, I'm going to assign a value <em>y</em> that is true if <code>x*y</code> is greater than 0.</p>
<div class="highlight"><pre><span class="n">data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">x1</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">x2</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<table border="1" class="dataframe table table-striped table-bordered">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-4.131299</td>
      <td>-2.266670</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.359900</td>
      <td>-3.169526</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-5.079496</td>
      <td>-7.030525</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8.475884</td>
      <td>-4.005687</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.072955</td>
      <td>-3.757722</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>

<h2>Visualize the input data</h2>
<p>Seaborn provides a <a href="http://seaborn.pydata.org/generated/seaborn.lmplot.html">function</a> that gives me exactly the visualization that I want:</p>
<div class="highlight"><pre><span class="n">seaborn</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span><span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>&lt;seaborn.axisgrid.FacetGrid at 0x7efd8407dd68&gt;
</pre></div>


<p><img alt="png" src="images/basic_keras_example/output_23_1.png" /></p>
<p>So we have two classes, and we're going to see if we can create a neural network that can distinguish between the two.</p>
<h2>Create training data and test data</h2>
<p>We assign 80% of the data to the training set, with the remaining 20% left over for testing the accuracy of our hypothesis.</p>
<div class="highlight"><pre><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>(800, 200)
</pre></div>


<p>Keras seems to require input data in the form of Numpy arrays, so we extract those from our Pandas dataframe:</p>
<div class="highlight"><pre><span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span><span class="s1">&#39;x2&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>


<h2>Define a neural network</h2>
<p>Now we can use Keras to define our network. I'm going to specify a network with an input layer, an output layer, and a 4-node hidden layer.</p>
<div class="highlight"><pre><span class="n">model</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
</pre></div>


<h2>Train the network</h2>
<p>This is the bit that would take considerably more lines of code in a lower-level library.  I can tweak parameters such as the cost function, the optimizer and so on. Here I choose a mean-squared-error cost function and a stochastic gradient descent optimizer.</p>
<p>I haven't yet figured out how to change the learning rate, which would be very helpful to know.</p>
<div class="highlight"><pre><span class="o">%%</span><span class="n">time</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>
          <span class="n">Y_train</span><span class="p">,</span>
          <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>CPU times: user 3.26 s, sys: 40 ms, total: 3.3 s
Wall time: 3.34 s
</pre></div>


<h2>Having trained the network, check it against the test data.</h2>
<p><code>plotPrediction</code> runs the <code>predict_classes</code> method to attempt to classify the test data we provide, and then displays its guesses:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">plotPrediction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">model</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">ix</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

    <span class="n">d</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">d</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="n">matches</span> <span class="o">=</span> <span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">Y</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span> <span class="n">matches</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">matches</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: {}%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>        <span class="c1">#I&#39;d rather compute an F-Score here.</span>

    <span class="n">seaborn</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span><span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">plotPrediction</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">91.5</span><span class="o">%</span>
</pre></div>


<p><img alt="png" src="images/basic_keras_example/output_36_1.png" /></p>
<h2>Conclusion</h2>
<p>So we see that after 250 training cycles, the network can mostly correctly identify input data.</p>
<p>Because the network is initialized with random data at the beginning of every run, sometimes I get better results than this and sometimes worse.  And Keras gives me many ways of quickly tweaking my algorithm - I can adjust the number of nodes in each layer, the number of layers, the activation function, the cost function, the number of training cycles, the test/training split and so on.  </p>
<p>Next I'd like to figure out how to adjust regularization parameters and the learning rate, and explore how that affects the efficiency of the network.</p>
<h3>Source</h3>
<p>The source for this post is <a href="https://github.com/trvrm/notebooks/blob/master/Basic%20Keras%20example.ipynb">available here on github</a></p>
                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/using-tensorflow-to-compute-gradients.html">Using TensorFlow to compute gradients</a></h2>
                
                
                <div class="entry-content">

                    <p>I tried the basic linear regression example from <a href="https://medium.com/all-of-us-are-belong-to-machines/the-gentlest-introduction-to-tensorflow-248dc871a224#.8429xmd7s">this article</a>.  I was quite surprised by this line:</p>
<div class="highlight"><pre><span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.0000001</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>                       
</pre></div>


<p>because it didn't seem to require me to tell the <code>GradientDescentOptimizer</code> what the first derivative of my cost function is.  Previously when I've used gradient descent, I've had to manually specify what the gradients with respect to my parameters as well as the cost function.</p>
<p>A bit of reading indicates that TensorFlow can <a href="https://www.tensorflow.org/api_docs/python/train/gradient_computation">compute gradients</a> for a given computation graph.  Let's have a look at a basic example. </p>
<div class="highlight"><pre><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>


<div class="highlight"><pre><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">pi</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">mp</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
</pre></div>


<p>We'll compute the derivative of the sin function over the range 0 to <code>2*pi</code></p>
<div class="highlight"><pre><span class="n">x_</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">pi</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<p>I'm still learning the relationship between Python variables and TensorFlow placeholders.</p>
<p>Here <code>x_</code> and <code>y_</code> are Python variables, <code>x</code> and <code>y</code> are TensorFlow tensors</p>
<div class="highlight"><pre><span class="n">x</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">x</span>
</pre></div>


<div class="highlight"><pre>&lt;tf.Tensor &#39;Placeholder_3:0&#39; shape=&lt;unknown&gt; dtype=float32&gt;
</pre></div>


<div class="highlight"><pre><span class="n">y</span>
</pre></div>


<div class="highlight"><pre>&lt;tf.Tensor &#39;Sin_3:0&#39; shape=&lt;unknown&gt; dtype=float32&gt;
</pre></div>


<p>Now we ask TensorFlow to compute both the <code>sin</code> function AND the first derivative.  </p>
<div class="highlight"><pre><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span><span class="n">x_</span><span class="p">}</span>
    <span class="n">y_</span>  <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">),</span><span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
    <span class="n">gradient</span><span class="o">=</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span class="n">mp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="n">y_</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="n">gradient</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="images/tensorflow_gradient/output_12_1.png" /></p>
<p>Note that I haven't had to declare anywhere that the first derivative of <code>sine(x)</code> is <code>cosine(x)</code>. TensorFlow seems to be able to figure that out analytically, which is pretty cool.</p>
                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/fractal-dimension.html">Fractal Dimension</a></h2>
                
                
                <div class="entry-content">

                    <p>Inspired by the <a href="https://www.youtube.com/watch?v=bSfe5M_zG2s">keynote</a> given at PyCon Portland by K Lars Lohn,, I wanted to try my hand 
at computing the fractal dimension of a few different images.</p>
<p>This is a very simple implementation of a <a href="https://en.wikipedia.org/wiki/Minkowski%E2%80%93Bouligand_dimension">box counting</a> algorithm.</p>
<p>A couple of ideas are borrowed from https://github.com/twobraids/fracdim.</p>
<p>First some imports:</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span>  <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">linregress</span>
</pre></div>


<p>Then a function to create simple black and white images.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">bw</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">gray</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;L&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gray</span><span class="o">.</span><span class="n">point</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">x</span><span class="o">&lt;</span><span class="mi">128</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">)</span>
</pre></div>


<p>Some sample images.  Basically, I expect the fractal dimension of the Canadian
coastline to be higher than that of, say, a square.</p>
<div class="highlight"><pre><span class="n">texas</span><span class="o">=</span><span class="n">bw</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;./images/texas.gif&#39;</span><span class="p">))</span>
<span class="n">tree</span><span class="o">=</span><span class="n">bw</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;./images/tree.jpg&#39;</span><span class="p">))</span>
<span class="n">canada</span><span class="o">=</span><span class="n">bw</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;./images/Canada.png&#39;</span><span class="p">))</span>
<span class="n">square</span><span class="o">=</span><span class="n">bw</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;./images/square.jpg&#39;</span><span class="p">))</span>
</pre></div>


<p>At various different scales, I want to divide each image up into squares and 
then count how many squares have at least one black pixel in them.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">interesting</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="c1">#true if any data is 0, i.e. black</span>
    <span class="k">return</span> <span class="mi">0</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">getdata</span><span class="p">())</span>
</pre></div>


<p>This function chops an image up into </p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">interesting_box_count</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
    <span class="n">width</span><span class="p">,</span><span class="n">height</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">size</span>

    <span class="n">interesting_count</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">box_count</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">width</span><span class="o">/</span><span class="n">length</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">height</span><span class="o">/</span><span class="n">length</span><span class="p">)):</span>
            <span class="n">C</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">length</span><span class="p">,</span><span class="n">y</span><span class="o">*</span><span class="n">length</span><span class="p">,</span><span class="n">length</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">length</span><span class="o">*</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">chopped</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
            <span class="n">box_count</span><span class="o">+=</span><span class="mi">1</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">interesting</span><span class="p">(</span><span class="n">chopped</span><span class="p">)):</span>
                <span class="n">interesting_count</span><span class="o">+=</span><span class="mi">1</span>        

    <span class="k">assert</span> <span class="n">box_count</span>
    <span class="k">assert</span> <span class="n">interesting_count</span>
    <span class="k">return</span> <span class="n">interesting_count</span>
</pre></div>


<p>This returns pairs of numbers. One represents the scale, the other the (log) count 
of boxes at that scale that have black pixels in them.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">getcounts</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">length</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">while</span><span class="p">(</span><span class="n">length</span><span class="o">&gt;</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">interesting</span> <span class="o">=</span> <span class="n">interesting_box_count</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">length</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">length</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">interesting</span><span class="p">)</span>
        <span class="n">length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">length</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">counts</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">getcounts</span><span class="p">(</span><span class="n">image</span><span class="p">),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span class="k">def</span> <span class="nf">dimension</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">frame</span><span class="o">=</span><span class="n">counts</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">linregress</span><span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">x</span><span class="p">,</span><span class="n">frame</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</pre></div>


<p>And finally, armed with lists of pairs, we compute the slope we'd get if we 
plotted them against each other.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">analyse</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">c</span><span class="o">=</span><span class="n">counts</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Fractal Dimension:&quot;</span><span class="p">,</span><span class="n">linregress</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">x</span><span class="p">,</span><span class="n">c</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">slope</span><span class="p">)</span>
</pre></div>


<h3>Results</h3>
<div class="highlight"><pre><span class="n">square</span>
</pre></div>


<p><img alt="png" src="images/fractal_dimension/output_10_0.png" width="300" height="300"></p>
<div class="highlight"><pre><span class="n">analyse</span><span class="p">(</span><span class="n">square</span><span class="p">)</span> 
</pre></div>


<div class="highlight"><pre>Fractal Dimension: 1.26420823227
</pre></div>


<div class="highlight"><pre><span class="n">texas</span>
</pre></div>


<p><img alt="png" src="images/fractal_dimension/output_12_0.png" width="300" height="300"></p>
<div class="highlight"><pre><span class="n">analyse</span><span class="p">(</span><span class="n">texas</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>Fractal Dimension: 1.45764518178
</pre></div>


<div class="highlight"><pre><span class="n">canada</span>
</pre></div>


<p><img alt="png" src="images/fractal_dimension/output_14_0.png" width="300" height="300"></p>
<div class="highlight"><pre><span class="n">analyse</span><span class="p">(</span><span class="n">canada</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>Fractal Dimension: 1.52450994232
</pre></div>


<div class="highlight"><pre><span class="n">tree</span>
</pre></div>


<p><img alt="png" src="images/fractal_dimension/output_16_0.png" width="300" height="300"></p>
<div class="highlight"><pre><span class="n">analyse</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>Fractal Dimension: 1.82487974473
</pre></div>


<p><strong>Which is exactly what we expected.</strong></p>
<p>As K Lars Lohn said in his keynote, it's very rewarding when you try something out in Python and the result actually matches neatly up with the theory!</p>
                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/new-blog-theme.html">New Blog Theme</a></h2>
                
                
                <div class="entry-content">

                    <p>Yesterday I discovered the <a href="http://bulma.io/">Bulma</a> CSS library.  It seems to be basically 'bootstrap for the flexbox world.'</p>
<p>Given that Bootstrap version 4 has been promising us Flexbox support for nearly a year now, I think Bulma could be my
new best CSS friend.  Of course, I won't be able to use it anywhere where I have to support even reasonably old
browsers, but so far it's been very pleasant to work with.</p>
<p>I also used this opportunity to learn how to <a href="http://docs.getpelican.com/en/3.1.1/themes.html">create themes for Pelican</a>.  I basically took the 'simple' theme from the Pelican distribution and systematically rewrote each template
to use Bulma classes.  Here's an example from the <code>article.html</code> template</p>
<div class="highlight"><pre><span class="nt">&lt;section</span> <span class="na">class=</span><span class="s">&quot;section&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">&quot;container&quot;</span><span class="nt">&gt;</span>
        <span class="nt">&lt;p</span> <span class="na">class=</span><span class="s">&quot;subtitle is-4&quot;</span><span class="nt">&gt;</span>
            <span class="cp">{{</span> <span class="nv">article.locale_date</span> <span class="cp">}}</span>
        <span class="nt">&lt;/p&gt;</span>

        <span class="nt">&lt;h2</span> <span class="na">class=</span><span class="s">&quot;title is-2&quot;</span><span class="nt">&gt;</span>
            <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">&quot;</span><span class="cp">{{</span> <span class="nv">SITEURL</span> <span class="cp">}}</span><span class="s">/</span><span class="cp">{{</span> <span class="nv">article.url</span> <span class="cp">}}</span><span class="s">&quot;</span> <span class="na">rel=</span><span class="s">&quot;bookmark&quot;</span> <span class="na">title=</span><span class="s">&quot;Permalink to </span><span class="cp">{{</span> <span class="nv">article.title</span><span class="o">|</span><span class="nf">striptags</span> <span class="cp">}}</span><span class="s">&quot;</span><span class="nt">&gt;</span>
                <span class="cp">{{</span> <span class="nv">article.title</span> <span class="cp">}}</span>
            <span class="nt">&lt;/a&gt;</span>
        <span class="nt">&lt;/h2&gt;</span>
        ...
</pre></div>
                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/pelican-atom-and-markdown.html">Pelican, Atom and Markdown</a></h2>
                
                
                <div class="entry-content">

                    <p>I've been using reStructured text in general to write this blog, but I think I'm
going to be switching to Markdown.  As an experiment, I'm writing this post in Markdown.</p>
<p>I'm also writing it in the <a href="https://atom.io/">Atom text editor</a>, which has really come on a
long way since I last tried it.  Specifically, it includes a Markdown preview function, so
I can see the effects of the markup that I'm writing as I write it.</p>
<p>Mostly, I want a rapid way of creating and publishing code snippets, without the mental
overhead of switching between markup languages. Although reStructured text and markdown
are broadly similar, there are subtle differences between them when it comes to things
like syntax highlighting.  But I've discovered today that if I use the triple-backtick
syntax, I can get the same output from Pelican, Atom, and IPython notebooks.</p>
<p>So</p>
<div class="highlight"><pre>    ```python
    def syntax(highlighting=True):
        return &quot;cool huh?&quot;
    ```
</pre></div>


<p>yields</p>
<div class="highlight"><pre> <span class="k">def</span> <span class="nf">syntax</span><span class="p">(</span><span class="n">highlighting</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
   <span class="k">return</span> <span class="s2">&quot;cool huh?&quot;</span>
</pre></div>


<p>And if I paste that into a markdown cell in an IPython notebook, I get the same effect, as
can be seen <a href="https://github.com/trvrm/notebooks/blob/master/Markdown%20Demo.ipynb">here</a></p>
<p>So this seems to be the general way that the open-source ecosystem is going: Markdown
allows me to use the same syntax for my GitHub documentation, my IPython notebooks, and
my blog posts.  </p>
<p>I do use <strong>Sphinx</strong> in various places for Python code documentation, so that will still
require reStructured text, but elsewhere I think Markdown is the way to go</p>
                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/asynchronous-python.html">Asynchronous Python</a></h2>
                
                
                <div class="entry-content">

                    <p>It's possible to get python to do node-like non-blocking requests, this could
take away one of the key reasons for using node.</p>
<p>The following is a full bottle-based python web application.</p>
<p>A client can sucessfully call /test while another client is waiting for
/slowproxy to return a result from a slow web service.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">gevent</span> <span class="kn">import</span> <span class="n">monkey</span><span class="p">;</span> <span class="n">monkey</span><span class="o">.</span><span class="n">patch_all</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">bottle</span> <span class="kn">import</span> <span class="n">route</span><span class="p">,</span> <span class="n">run</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="nd">@route</span><span class="p">(</span><span class="s1">&#39;/sleep/&lt;seconds:int&gt;&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sleep</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;Slept For {0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seconds</span><span class="p">)</span>

<span class="nd">@route</span><span class="p">(</span><span class="s1">&#39;/test&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
     <span class="k">return</span> <span class="s1">&#39;test&#39;</span>


<span class="nd">@route</span><span class="p">(</span><span class="s1">&#39;/slowproxy/&lt;seconds:int&gt;&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">slowproxy</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">requests</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;https://s.nooro.com/sleeptest.php?seconds=</span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">seconds</span>
    <span class="n">response</span><span class="o">=</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span>

<span class="n">run</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;0.0.0.0&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8080</span><span class="p">,</span><span class="n">server</span><span class="o">=</span><span class="s1">&#39;gevent&#39;</span><span class="p">)</span>
</pre></div>
<p>My first attempt used grequests, but apparently that's not even necessary.</p>
<p>I guess that the call to monkey.patch_all() even patches the socket code
that requests uses.  I'm very impressed.</p>

                    
                </div>  
                
                
            </article>
            <hr/>
            <article>
                <h2><a href="/coffeescript.html">CoffeeScript</a></h2>
                
                
                <div class="entry-content">

                    <p>Through a bizarre twist of history, the entire client-side web runs on a <a class="reference external" href="http://en.wikipedia.org/wiki/Brendan_Eich#Netscape_and_JavaScript">language</a>
that was thrown together in 10 days.</p>
<p>Despite huge investments in their own proprietary technology by the likes of Sun
Microsystems, Adobe and Microsoft, this weird little spinoff of <strong>self</strong> and <strong>scheme</strong>
is everywhere, while client-side Java, ActiveX and Flash fade into obscurity.</p>
<p>Unsurprisingly for a language developed so quickly, Javascript is pretty ugly.
I'm fond of saying that it's a horrible language, with a really nice language
inside trying to get out.  It gets some things, like scoping rules, very, very
wrong.  But it got other things, like anonymous functions, exactly right, long before
they were adopted in Java, C#, or C++.  Even Python, my favourite language ever,
doesn't get them quite right.</p>
<p>Several people have attempted to build a nicer syntax on top of the javascript
virtual machine.  In fact, the <a class="reference external" href="https://github.com/jashkenas/coffeescript/wiki/List-of-languages-that-compile-to-JS">list</a> of languages that compile to JS is startlingly
big.</p>
<p>For the last couple of years I've been using <a class="reference external" href="http://coffeescript.org/">CoffeeScript</a> as my standard javascript syntax.</p>
<p>From the project page:</p>
<blockquote>
&quot;CoffeeScript is a little language that compiles into JavaScript.
Underneath that awkward Java-esque patina, JavaScript has always
had a gorgeous heart. CoffeeScript is an attempt to expose the
good parts of JavaScript in a simple way.&quot;</blockquote>
<p>and I think it achieves this admirably.  It doesn't solve <em>all</em> of javascript's problems -
you can still get into trouble with the Infamous Loop Problem, but it does make the language
considerably more succinct, mostly by stealing ideas from Python and Haskell.</p>
<div class="section" id="examples">
<h2>Examples</h2>
<p>Function definitions go from</p>
<div class="highlight"><pre><span class="kd">function</span> <span class="nx">d</span><span class="p">(</span><span class="nx">x</span><span class="p">){</span>
    <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="nx">x</span>
<span class="p">}</span>
</pre></div>
<p>to</p>
<div class="highlight"><pre><span class="nv">d = </span><span class="nf">(x) -&gt;</span> <span class="mi">2</span><span class="o">*</span><span class="nx">x</span>
</pre></div>
<p>This makes for very quick object construction:</p>
<div class="highlight"><pre><span class="nv">math =</span>
    <span class="nv">root: </span>  <span class="nb">Math</span><span class="p">.</span><span class="nx">sqrt</span>
    <span class="nv">square: </span><span class="nx">square</span>
    <span class="nv">cube: </span>  <span class="nf">(x) -&gt;</span> <span class="nx">x</span> <span class="o">*</span> <span class="nx">square</span> <span class="nx">x</span>
</pre></div>
<p>It also borrows Python's list comprehension syntax:</p>
<div class="highlight"><pre><span class="nx">values</span><span class="o">=</span><span class="p">(</span><span class="nx">option</span><span class="p">.</span><span class="nx">value</span> <span class="k">for</span> <span class="nx">option</span> <span class="k">in</span> <span class="nx">question</span><span class="p">.</span><span class="nx">options</span><span class="p">)</span>
</pre></div>
<p>The near complete absense of curly brackets saves a lot of wasted lines in
my source code, and enables me to see what's going on a lot clearer than in raw
javascript.  On the downside, I do find myself fairly regularly testing out code
snippets in the <a class="reference external" href="http://coffeescript.org/">CoffeeScript</a> online compiler to make sure that I've properly understood
how they will be interpreted.</p>
<p>Because CoffeeScript is a compiled language, to work with it effectively requires
integrating the compiler into your toolchain.  For my larger projects I've hand-written
a tool using Python's <a class="reference external" href="https://pypi.python.org/pypi/watchdog">Watchdog</a> package to monitor my source code directories and
output compiled javascript everytime a file changes.</p>
<p>As a nice little extra, my tool jams in a warning message wrapped in an <code class="code">
alert</code>
 call
if the compliation fails, so if I introduce a syntax error in my coffeescript, as soon
as I refresh the page that is using it I'll be presented with the source of the problem.</p>
</div>

                    
                </div>  
                
                
            </article>
            <hr/>

        <ul class="pagination">
                <li class="prev disabled"><a href="#">&laquo;</a></li>
                    <li class="active"><a
                            href="/category/software.html">1</a></li>
                    <li class=""><a
                            href="/category/software2.html">2</a></li>
                    <li class=""><a
                            href="/category/software3.html">3</a></li>
                <li class="next"><a
                        href="/category/software2.html">&raquo;</a></li>
        </ul>
        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>

<section class="well well-sm">
    <ul class="list-group list-group-flush">
            <li class="list-group-item"><h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
              <ul class="list-group" id="social">
                <li class="list-group-item"><a href="https://twitter.com/trvrm"><i class="fa fa-twitter-square fa-lg"></i> twitter</a></li>
              </ul>
            </li>





    </ul>
</section>
            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 trvrm
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>


</body>
</html>